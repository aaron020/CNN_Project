{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYg0vQ0ESznat431BeeFW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaron020/CNN_Project/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import keras.backend as K\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Eq_jFvBM4Lbc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROWS = 224\n",
        "COLS = 224\n",
        "CHANNELS = 3\n",
        "CLASSES = 2"
      ],
      "metadata": {
        "id": "bXooYRdIEZnr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pull in a dataset from your computer\n",
        "pathNameTraining = \"dog_cat/training_set/training_set\"\n",
        "pathNameTest = \"dog_cat/test_set/test_set\"\n",
        "\n",
        "#!unzip archive.zip\n",
        "Training_types = os.listdir(pathNameTraining)\n",
        "test_types = os.listdir(pathNameTest)\n",
        "\n",
        "print(\"Training folders = \" , Training_types)\n",
        "print(\"Test folders = \" , test_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcO8XIsu0ion",
        "outputId": "70eb9429-17e8-41f7-d74e-a6f73435e01b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training folders =  ['cats', 'dogs']\n",
            "Test folders =  ['cats', 'dogs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_image(file_path):\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "def prepare_data(images):\n",
        "    m = len(images)\n",
        "    X = np.zeros((m, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "    y = np.zeros((1, m), dtype=np.uint8)\n",
        "    for i, image_file in enumerate(images):\n",
        "        X[i,:] = read_image(image_file)\n",
        "        if 'dogs' in image_file.lower():\n",
        "            y[0, i] = 1\n",
        "        elif 'cats' in image_file.lower():\n",
        "            y[0, i] = 0\n",
        "    return X, y\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n"
      ],
      "metadata": {
        "id": "rciMLsMBEiZa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tack all the data from the datset \n",
        "TRAIN_DIR = []\n",
        "TEST_DIR = []\n",
        "\n",
        "for item in Training_types:\n",
        "  # get all the files from each folder \n",
        "  all_training = os.listdir(pathNameTraining + '/' + item)\n",
        "  #Half the dataset due to ram problems\n",
        "  for fw in range(0,1000):\n",
        "    #Some of the training set is not jpg which causes errors for the resize\n",
        "    if 'jpg' in all_training[fw]:\n",
        "      name = pathNameTraining + '/' + item + '/' + all_training[fw]\n",
        "      TRAIN_DIR.append(name)\n",
        "\n",
        "\n",
        "for item in test_types:\n",
        "  # get all the files from each folder \n",
        "  all_test = os.listdir(pathNameTest + '/' + item)\n",
        "  #Half the dataset due to ram problems\n",
        "  for fw in range(0,500):\n",
        "    if 'jpg' in all_test[fw]:\n",
        "      name = pathNameTest + '/' + item + '/' + all_test[fw]\n",
        "      TEST_DIR.append(name)\n",
        "\n",
        "\n",
        "print(len(TRAIN_DIR))\n",
        "print(len(TEST_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMKj3rlS5eOQ",
        "outputId": "9b4d6c53-4cd5-4b88-a0f8-29f535d7c126"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x, train_set_y = prepare_data(TRAIN_DIR)\n",
        "test_set_x, test_set_y = prepare_data(TEST_DIR)\n",
        "\n",
        "X_train = train_set_x/255\n",
        "X_test = test_set_x/255\n",
        "\n",
        "Y_train = convert_to_one_hot(train_set_y, CLASSES).T\n",
        "Y_test = convert_to_one_hot(test_set_y, CLASSES).T"
      ],
      "metadata": {
        "id": "NMRl_F2jE3Qf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"number of training examples =\", X_train.shape[0])\n",
        "print (\"number of test examples =\", X_test.shape[0])\n",
        "print (\"X_train shape:\", X_train.shape)\n",
        "print (\"Y_train shape:\", Y_train.shape)\n",
        "print (\"X_test shape:\", X_test.shape)\n",
        "print (\"Y_test shape:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZi8W3C3NdmL",
        "outputId": "fe71e55c-9945-4516-b063-f5485da2a77d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 2000\n",
            "number of test examples = 999\n",
            "X_train shape: (2000, 224, 224, 3)\n",
            "Y_train shape: (2000, 2)\n",
            "X_test shape: (999, 224, 224, 3)\n",
            "Y_test shape: (999, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. We'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "MXopuwDiNnrq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    \n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "s7wtYBxfNtct"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def ResNet50(input_shape = (224, 224, 3), classes = 2):   \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL.\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "ivb2pGCyNzWP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)"
      ],
      "metadata": {
        "id": "VoJuNZxON5Hj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JBiCTNLAN7eL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs = 3, batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1FRPDXjN9YY",
        "outputId": "6ca503b3-1f98-49c1-8833-74322cd91dc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "32/32 [==============================] - 879s 27s/step - loss: 2.9535 - accuracy: 0.5040\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 878s 27s/step - loss: 1.3808 - accuracy: 0.5620\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 875s 27s/step - loss: 1.6534 - accuracy: 0.5450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43b8ca59d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}